{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Solving Linear Systems via Gaussian Elimination"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We remember that the problem we are trying to solve is the system of linear equations written as\n",
      "\n",
      "\\begin{equation}\n",
      "  A {\\bf x} = {\\bf b}.\n",
      "\\end{equation}\n",
      "\n",
      "This is equivalent to $n$ simultaneous linear equations for the $n$ unknowns $x_i$. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first class of methods we consider are **direct**: a finite number of steps are followed which, in principle, result in the correct answer."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Most direct methods use the same core approach: convert the linear system to an equivalent problem that is easy to solve. \n",
      "\n",
      "So the first thing we should do is consider which linear systems are easy to solve. Obviously if the matrix is diagonal it is easy to solve. More generally, it is straightforward to solve a linear system if the matrix is *triangular*.\n",
      "\n",
      "As an example, consider\n",
      "\n",
      "\\begin{equation}\n",
      "  \\begin{pmatrix} 1 & 2 & 3 \\\\ 0 & 4 & 5 \\\\ 0 & 0 & 6 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 6 \\\\ 9 \\\\ 6 \\end{pmatrix}.\n",
      "\\end{equation}\n",
      "\n",
      "Perform **back substitution** by solving from the bottom up. That is, read off the equation defined by the bottom row of the matrix:\n",
      "\n",
      "\\begin{equation}\n",
      "  6 x_3 = 6 \\qquad \\implies \\qquad x_3 = 1.\n",
      "\\end{equation}\n",
      "\n",
      "Then read off the equation defined by the second row of the matrix, using the information found for $x_3$:\n",
      "\n",
      "\\begin{equation}\n",
      "  4 x_2 + 5 x_3 = 9 \\qquad \\implies \\qquad 4 x_2 = 4 \\qquad \\implies \\qquad x_2 = 1.\n",
      "\\end{equation}\n",
      "\n",
      "Finally, read off the equation defined by the first row of the matrix, using the information found for $x_2$ and $x_3$:\n",
      "\n",
      "\\begin{equation}\n",
      "  x_1 + 2 x_2 + 3 x_3 = 6 \\qquad \\implies \\qquad x_1 = 1.\n",
      "\\end{equation}\n",
      "\n",
      "Back substitution will work for any *upper* triangular matrix, provided that no diagonal element is zero (guaranteed if the matrix is non-singular). If the matrix is lower triangular we would start at the top and work down, using **forward** substitution."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Gaussian elimination"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, we need to be able to convert our original linear system to an equivalent system in triangular form - here we will aim to construct an upper triangular matrix. By equivalent, we mean that the solution is the same."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Think of each row corresponding to a single linear equation, and each column corresponding to a single unknown variable. Then we see that there are three basic operations that can be performed without changing the solution:\n",
      "\n",
      "1. Multiply any row by a non-zero scalar (equivalent to scaling the whole equation).\n",
      "2. Swap two rows (equivalent to changing the order of the equations).\n",
      "3. Swap two columns (equivalent to changing the order of the unknown variables).\n",
      "\n",
      "We will concentrate on the first two operations, as swapping the columns requires us to keep track of which entries of the final solution vector correspond to which unknown variables."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To ensure that the operations are performed consistently to both the entries of the matrix $A$ *and* the right hand side vector ${\\bf b}$, it is best to construct the **augmented matrix** $\\left( A | {\\bf b} \\right)$. All operations are applied to this matrix, which has $n+1$ columns and $n$ rows."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Basic algorithm"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The basic algorithm takes the augmented matrix with arbitrary coefficients and returns an upper triangular augemented matrix. This can then be split into the form of the original system and solved by back substitution.\n",
      "\n",
      "The algorithm considers each row in turn. Assume \n",
      "\n",
      "1. We are looking at row $i$, where $1 \\le i \\le n$;\n",
      "2. The previous steps of the algorithm mean that the coefficients in the first $i-1$ columns of row $i$, and all rows below row $i$ are zero. \n",
      "3. The $i^{\\text{th}}$ entry of row $i$, $a_{i, i}$ is non-zero.\n",
      "\n",
      "Then we can eliminate all coefficients in column $i$ in the rows below $i$ by subtracting a suitable of row $i$. Explicitly, consider row $j$ where $i < j \\le n$. For all coefficients in row $j$, i.e. for $a_{j, k}$ with $1 \\le k \\le n$, we replace the coefficient by\n",
      "\n",
      "\\begin{equation}\n",
      "  a_{j, k} \\rightarrow a_{j, k} - \\frac{a_{j, i}}{a_{i, i}} a_{i, k}.\n",
      "\\end{equation}\n",
      "\n",
      "We see that when $k = i$ the coefficient $a_{j, i}$ will be set to zero, as required.\n",
      "\n",
      "If we repeat this algorithm for all rows $i$ then we will have constructed a triangular matrix."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us write this algorithm explicitly in code."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "def GaussianEliminationReduction(A, b):\n",
      "    \"\"\"\n",
      "    Simple Gaussian Elimination algorithm. Solves linear system A x = b, assuming well-conditioned square matrix A.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    \n",
      "    A : float, numpy array, 2d.\n",
      "        Square matrix, size n x n.\n",
      "    b : float, numpy array, 1d.\n",
      "        RHS vector, size n (must conform with A).\n",
      "    \"\"\"\n",
      "    \n",
      "    # Store size of system\n",
      "    n = len(b)\n",
      "    assert(np.all(A.shape == (n, n)))\n",
      "    \n",
      "    # Form augmented matrix\n",
      "    aug = np.hstack((A, b.reshape(n,1)));\n",
      "    \n",
      "    # Loop over rows\n",
      "    for i in range(n):\n",
      "        # Loop over rows below i\n",
      "        for j in range(i+1, n):\n",
      "            aug[j, :] = aug[j, :] - aug[j, i] / aug[i, i] * aug[i, :]\n",
      "    \n",
      "    # Return the separated, reduced, matrix and right hand side vector.\n",
      "    return (aug[:,:-1], aug[:, -1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now test the algorithm on some simple examples. The first is already in triangular form as above - just checks that it doesn't do anything stupid!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.array([[1.0, 2.0, 3.0], \\\n",
      "              [0.0, 4.0, 5.0], \\\n",
      "              [0.0, 0.0, 6.0]])\n",
      "b = np.array([6.0, 9.0, 6.0])\n",
      "\n",
      "(A1, b1) = GaussianEliminationReduction(A, b)\n",
      "print(\"Resulting triangular matrix is \\n{}.\\n Right hand side vector becomes {}.\\n\".format(A1, b1))\n",
      "\n",
      "C = np.array([[3.0, 0.0, 1.0], \\\n",
      "              [6.0, 2.0, 4.0], \\\n",
      "              [9.0, 2.0, 6.0]])\n",
      "d = np.array([4.0, 10.0, 15.0])\n",
      "\n",
      "(A2, b2) = GaussianEliminationReduction(C, d)\n",
      "print(\"Resulting triangular matrix is \\n{}.\\n Right hand side vector becomes {}.\\n\".format(A2, b2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resulting triangular matrix is \n",
        "[[ 1.  2.  3.]\n",
        " [ 0.  4.  5.]\n",
        " [ 0.  0.  6.]].\n",
        " Right hand side vector becomes [ 6.  9.  6.].\n",
        "\n",
        "Resulting triangular matrix is \n",
        "[[ 3.  0.  1.]\n",
        " [ 0.  2.  2.]\n",
        " [ 0.  0.  1.]].\n",
        " Right hand side vector becomes [ 4.  2.  1.].\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Pivoting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, the simple algorithm above does not work robustly. As a simple example, consider the system below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "E = np.array([[1.0, 1.0, 1.0], \\\n",
      "              [0.0, 0.0, 2.0], \\\n",
      "              [0.0, 1.0, 1.0]])\n",
      "f = np.array([1.0, 1.0, 2.0])\n",
      "\n",
      "(A3, b3) = GaussianEliminationReduction(E, f)\n",
      "print(\"Resulting triangular matrix is \\n{}.\\n Right hand side vector becomes {}.\\n\".format(A3, b3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resulting triangular matrix is \n",
        "[[  1.   1.   1.]\n",
        " [  0.   0.   2.]\n",
        " [ nan  nan -inf]].\n",
        " Right hand side vector becomes [  1.   1. -inf].\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:27: RuntimeWarning: divide by zero encountered in double_scalars\n",
        "-c:27: RuntimeWarning: invalid value encountered in multiply\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The algorithm has failed as the matrix does not satisfy the assumptions necessary: in particular, the element $a_{2, 2}$ is zero."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can simply avoid this problem by swapping rows. In this instance we would swap the second and third row and the algorithm would work (in this case, swapping the second and third rows puts the matrix in triangular form)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, there is a similar problem if an entry is very small, but non-zero. Consider the problem\n",
      "\n",
      "\\begin{equation}\n",
      "  \\left( \\begin{array}{c c|c} \\varepsilon & 1 & 1 \\\\ 1 & 1 & 2 \\end{array} \\right) \\rightarrow \\left( \\begin{array}{c c|c} \\varepsilon & 1 & 1 \\\\ 0 & 1 - \\varepsilon^{-1} & 2 - \\varepsilon^{-1} \\end{array} \\right)\n",
      "\\end{equation}\n",
      "\n",
      "which has been reduced to triangular form using Gaussian elimination. If $\\varepsilon$ is very small then the terms $\\varepsilon^{-1}$ will dominate, making the problem approximately\n",
      "\n",
      "\\begin{equation}\n",
      "  \\left( \\begin{array}{c c|c} \\varepsilon & 1 & 1 \\\\ 0 & - \\varepsilon^{-1} & - \\varepsilon^{-1} \\end{array} \\right) \\quad \\implies \\quad {\\bf x} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}.\n",
      "\\end{equation}\n",
      "\n",
      "The correct answer *should* be ${\\bf x} = (1, 1)^T$. There is nothing wrong with the condition number. The problem is the Gaussian Elimination step where it divides through by $\\varepsilon$, a very small number."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To avoid both these problems, the standard technique is to **pivot**, or use **pivoting**. At each stage in the algorithm we are working with row $i$ and looking to eliminate the entries in rows $j > i$. The first step is to check if there is a row $j > i$ with a larger (in magnitude) coefficient in column $i$. If so, we swap the rows. Note that we cannot consider rows above $i$ in the matrix, as these may have non-zero entries in columns $<i$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We modify the algorithm to include pivoting."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GaussianEliminationPivotingReduction(A, b):\n",
      "    \"\"\"\n",
      "    Simple Gaussian Elimination algorithm with pivoting. Solves linear system A x = b, \n",
      "    assuming well-conditioned square matrix A.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    \n",
      "    A : float, numpy array, 2d.\n",
      "        Square matrix, size n x n.\n",
      "    b : float, numpy array, 1d.\n",
      "        RHS vector, size n (must conform with A).\n",
      "    \"\"\"\n",
      "    \n",
      "    # Store size of system\n",
      "    n = len(b)\n",
      "    assert(np.all(A.shape == (n, n)))\n",
      "    \n",
      "    # Form augmented matrix\n",
      "    aug = np.hstack((A, b.reshape(n,1)));\n",
      "    \n",
      "    # Loop over rows\n",
      "    for i in range(n):\n",
      "        # Find the row with largest magnitude, and then swap the rows.\n",
      "        max_row = np.argmax(aug[i:, i])\n",
      "        if (max_row): # Only swap rows if the maximum is not this row. \\\n",
      "                      # NOTE: the max_row is counted relative to i, so max_row = 0 => row i.\n",
      "            tmp               = np.copy(aug[i, :])\n",
      "            aug[i, :]         = np.copy(aug[i+max_row, :])\n",
      "            aug[i+max_row, :] = np.copy(tmp)\n",
      "        # Loop over rows below i\n",
      "        for j in range(i+1, n):\n",
      "            aug[j, :] = aug[j, :] - aug[j, i] / aug[i, i] * aug[i, :]\n",
      "    \n",
      "    # Return the separated, reduced, matrix and right hand side vector.\n",
      "    return (aug[:,:-1], aug[:, -1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check on the previously failing case."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(A4, b4) = GaussianEliminationPivotingReduction(E, f)\n",
      "print(\"Resulting triangular matrix is \\n{}.\\n Right hand side vector becomes {}.\\n\".format(A4, b4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resulting triangular matrix is \n",
        "[[ 1.  1.  1.]\n",
        " [ 0.  1.  1.]\n",
        " [ 0.  0.  2.]].\n",
        " Right hand side vector becomes [ 1.  2.  1.].\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Special case - tridiagonal systems"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tridiagonal systems turn up frequently in the solution of differential equations, particularly when using finite difference methods.\n",
      "      \n",
      "Consider the simple $4 \\times 4$ system\n",
      "      \n",
      "\\begin{equation}\n",
      "        \\begin{pmatrix}\n",
      "          2 & 1 & 0 & 0 \\\\\n",
      "          1 & 2 & 1 & 0 \\\\\n",
      "          0 & 1 & 2 & 1 \\\\\n",
      "          0 & 0 & 1 & 2\n",
      "        \\end{pmatrix}\n",
      "        \\begin{pmatrix}\n",
      "          x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4\n",
      "        \\end{pmatrix}\n",
      "        =\n",
      "        \\begin{pmatrix}\n",
      "          -1 \\\\ 0 \\\\ 0 \\\\ -1\n",
      "        \\end{pmatrix}.\n",
      "\\end{equation}\n",
      "      \n",
      "We proceed as we would with Gaussian elimination: remove the (single) coefficient below the diagonal first, rescaling as we go:\n",
      "      \n",
      "\\begin{equation}\n",
      "        \\begin{pmatrix}\n",
      "          1 & \\tfrac{1}{2} & 0 & 0 \\\\\n",
      "          0 & 1 & \\tfrac{2}{3} & 0 \\\\\n",
      "          0 & 0 & 1 & \\tfrac{3}{4} \\\\\n",
      "          0 & 0 & 0 & 1\n",
      "        \\end{pmatrix}\n",
      "        \\begin{pmatrix}\n",
      "          x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4\n",
      "        \\end{pmatrix}\n",
      "        =\n",
      "        \\begin{pmatrix}\n",
      "          -\\tfrac{1}{2} \\\\ \\tfrac{1}{3} \\\\ -\\tfrac{1}{4} \\\\ -\\tfrac{3}{5}\n",
      "        \\end{pmatrix},\n",
      "\\end{equation}\n",
      "      \n",
      "and then use back-substitution to get\n",
      "      \n",
      "\\begin{equation}\n",
      "        \\left\\{\n",
      "          \\begin{aligned}\n",
      "            x_4 & =-\\tfrac{3}{5} \\\\\n",
      "            x_3 & = \\tfrac{1}{5} \\\\\n",
      "            x_2 & = \\tfrac{1}{5} \\\\\n",
      "            x_1 & =-\\tfrac{3}{5}\n",
      "          \\end{aligned} \\right. .\n",
      "\\end{equation}\n",
      "\n",
      "The general formulation of this is the **Thomas algorithm**. It has the significant advantage that only the three non-trivial diagonals need to be stored and worked with. This can massively reduce the memory required."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}